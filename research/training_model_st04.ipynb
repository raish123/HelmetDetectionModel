{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "from src.Mask.Utils import SaveModel,read_yaml,create_directory\n",
    "from src.Mask.exceptions import CustomException\n",
    "from src.Mask.loggers import logger\n",
    "from src.Mask.Constants import *\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step3) update the entity file: entity file is nothing whatever parameter we have used in yaml file \n",
    "#we define them as classvariable \n",
    "@dataclass\n",
    "class TrainedModelConfig():\n",
    "    root_dirpath:Path\n",
    "    model_trained_dirpath:Path\n",
    "    data_dirpath:Path\n",
    "    all_param:dict\n",
    "    sequential_model_path:Path\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CallbackConfig():\n",
    "    #defining the class variable\n",
    "    root_dirpath:Path\n",
    "    tensorboard_log_dirpath:Path\n",
    "    model_checkpoint_path:Path\n",
    "    all_param:dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the configurationmanager file in this file we read the yaml file and create directories and\n",
    "#assigning value to the class variable and taking rtn as function\n",
    "class ConfigurationManager():\n",
    "    def __init__(self,config_filepath=CONFIG_FILEPATH,param_filepath=PARAM_FILEPATH):\n",
    "        self.config = read_yaml(config_filepath) #rtn value as configbox dictatonary\n",
    "        self.param = read_yaml(param_filepath)   #rtn value as configbox dictatonary\n",
    "\n",
    "        #creating main artifact directory\n",
    "        create_directory([self.config.artifact_root_dir]) #create artifacts folder \n",
    "\n",
    "    def get_call_model_config(self) ->CallbackConfig:\n",
    "        #initializing the local variable\n",
    "        config = self.config.prepare_callbacks\n",
    "        param = self.param\n",
    "        #getting dirname from this artifacts/callbacks/model_checkpoint/model.h5\n",
    "        ckpt_directory = os.path.dirname(config.model_checkpoint_path) #create this path artifacts/callbacks/model_checkpoint\n",
    "\n",
    "        #creating directory of callbacks\n",
    "        create_directory([config.root_dirpath,ckpt_directory]) #create directoy artifacts/callbacks/model_checkpoint\n",
    "\n",
    "        #creating an object of class variable and taking rtn as function\n",
    "        callback_config = CallbackConfig(\n",
    "            root_dirpath=config.root_dirpath,\n",
    "            tensorboard_log_dirpath=config.tensorboard_log_dirpath,\n",
    "            model_checkpoint_path=config.model_checkpoint_path,\n",
    "            all_param=param\n",
    "        )\n",
    "        return callback_config\n",
    "\n",
    "    def get_trained_model_config(self) ->TrainedModelConfig:\n",
    "        #initializing the local variable\n",
    "        config = self.config.model_training\n",
    "        param = self.param\n",
    "\n",
    "        #creating the directory model_training\n",
    "        create_directory([config.root_dirpath]) #it will create model_training directory in project structure\n",
    "\n",
    "        #creating an object of TrainedModelConfig class variable and assigning value to it and taking rtn as functiom\n",
    "        trained_model_config = TrainedModelConfig(\n",
    "            root_dirpath=config.root_dirpath,\n",
    "            model_trained_dirpath = config.model_trained_dirpath,\n",
    "            data_dirpath=config.data_dirpath,\n",
    "            all_param=param,\n",
    "            sequential_model_path=self.config.prepare_base_model.updated_base_model_path\n",
    "\n",
    "\n",
    "        )\n",
    "        return trained_model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step5)updating the component file in this file we create object for class variable and perform task accordingly\n",
    "from datetime import datetime\n",
    "class CallbackModel():\n",
    "    def __init__(self,callbackconfig:CallbackConfig):\n",
    "        self.callbackconfig = callbackconfig\n",
    "\n",
    "    @property\n",
    "    def _get_tensorboard_dir(self):\n",
    "        timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "        tensorboard_log_dir = os.path.join(self.callbackconfig.tensorboard_log_dirpath,f\"TB_{timestamp}.log\")\n",
    "\n",
    "        # Ensure the directory exists\n",
    "        os.makedirs(os.path.dirname(tensorboard_log_dir), exist_ok=True)\n",
    "\n",
    "        return tf.keras.callbacks.TensorBoard(\n",
    "            log_dir=tensorboard_log_dir,\n",
    "              histogram_freq=1, write_graph=True, write_images=True\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def _model_checkpoint(self):\n",
    "        return tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=self.callbackconfig.model_checkpoint_path,\n",
    "            monitor=\"val_loss\",\n",
    "            verbose = 1,\n",
    "            save_best_only=True\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def _early_stopping(self):\n",
    "        return tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            min_delta=self.callbackconfig.all_param.learning_rate,\n",
    "            patience=2,\n",
    "            verbose=1,\n",
    "            mode=\"auto\",\n",
    "            restore_best_weights=True,\n",
    "            start_from_epoch=0\n",
    "\n",
    "        )\n",
    "    \n",
    "    #creating main method callback\n",
    "    def callback(self):\n",
    "        return [\n",
    "            self._get_tensorboard_dir,\n",
    "            self._model_checkpoint,\n",
    "            self._early_stopping\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now updating the component file:- In this file we creating an object of class variable as instance\n",
    "#and performing task accordingly!!\n",
    "class ModelTraining():\n",
    "    def __init__(self,modelconfig:TrainedModelConfig):\n",
    "        self.modelconfig=modelconfig\n",
    "\n",
    "    #step1)loading the sequential model at which we have to have to perform training in it\n",
    "    def load_seq_model(self):\n",
    "        self.sequential_model = tf.keras.models.load_model(\n",
    "            filepath=self.modelconfig.sequential_model_path\n",
    "        )\n",
    "\n",
    "    #step2) Training the model by using Imagegenerator class or flowing the image through directory of tensorflow\n",
    "    #Imagegenerator class we used to perform scaling and zooming and also indirect we do preprocessing\n",
    "    def train_valid_generator(self):\n",
    "        datagenerator_kwarg = dict(\n",
    "            rescale=1./255,\n",
    "            validation_split=0.20\n",
    "        )\n",
    "\n",
    "        #creating keyward argument of dataflow_kwarg\n",
    "        dataflow_kwarg = dict(\n",
    "            target_size=self.modelconfig.all_param.input_shape[:-1],\n",
    "            batch_size=self.modelconfig.all_param.batch_size,\n",
    "            interpolation = \"bilinear\" #Bilinear interpolation is one of the options for smooth and resizing image.\n",
    "        )\n",
    "\n",
    "        #now generating test image by using tensorflow\n",
    "        valid_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            **datagenerator_kwarg\n",
    "        )\n",
    "\n",
    "        #now flowing the valid_image_generator through directory\n",
    "        self.valid_image_generator = valid_image_generator.flow_from_directory(\n",
    "            \n",
    "            directory=self.modelconfig.data_dirpath, #directory where we get image file\n",
    "            subset='validation',\n",
    "            shuffle=True,\n",
    "            **dataflow_kwarg\n",
    "        )\n",
    "\n",
    "\n",
    "        #now generating training image through augmentation\n",
    "        if self.modelconfig.all_param.augmentation:\n",
    "            train_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                **datagenerator_kwarg,\n",
    "                horizontal_flip=True,\n",
    "                vertical_flip=True,\n",
    "                rotation_range=40,\n",
    "                width_shift_range=0.20,\n",
    "                height_shift_range=0.20,\n",
    "                brightness_range=(0.9, 1.1),\n",
    "                shear_range=0.20,\n",
    "                zoom_range=0.20,\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            train_image_generator = valid_image_generator\n",
    "\n",
    "        self.train_image_generator = train_image_generator.flow_from_directory(\n",
    "            \n",
    "            directory=self.modelconfig.data_dirpath,\n",
    "            subset='training',\n",
    "            shuffle=True,\n",
    "            **dataflow_kwarg\n",
    "        )\n",
    "\n",
    "    #Now training or fitting the model\n",
    "    def train(self,callback_list:list):\n",
    "        self.steps_per_epoch = self.train_image_generator.samples // self.train_image_generator.batch_size\n",
    "        self.validation_steps = self.valid_image_generator.samples // self.valid_image_generator.batch_size\n",
    "\n",
    "        self.sequential_model.fit(\n",
    "            self.train_image_generator,\n",
    "            batch_size = self.modelconfig.all_param.batch_size,\n",
    "            epochs = self.modelconfig.all_param.epochs,\n",
    "            verbose = True,\n",
    "            validation_data = self.valid_image_generator,\n",
    "            initial_epoch = 0,\n",
    "            steps_per_epoch = self.steps_per_epoch,\n",
    "            validation_steps = self.validation_steps,\n",
    "            callbacks=callback_list\n",
    "\n",
    "        )\n",
    "\n",
    "        #saving the trained model in model checkpoint directory\n",
    "        SaveModel(filepath=Path(self.modelconfig.model_trained_dirpath),model=self.sequential_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\MaskImageDetection\\\\MaskDetectionModel\\\\research'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\MaskImageDetection\\\\MaskDetectionModel'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-02 19:37:19,249]-INFO-33-Yaml file config\\config.yaml reading\n",
      "[2024-10-02 19:37:19,258]-INFO-33-Yaml file param.yaml reading\n",
      "[2024-10-02 19:37:19,264]-INFO-49-Directory artifacts/callbacks created\n",
      "[2024-10-02 19:37:19,281]-INFO-49-Directory artifacts/callbacks/model_checkpoint created\n",
      "[2024-10-02 19:37:19,283]-INFO-49-Directory artifacts/model_training created\n",
      "Found 12 images belonging to 2 classes.\n",
      "Found 53 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.7104 - accuracy: 0.5581\n",
      "Epoch 1: val_loss improved from inf to 0.80436, saving model to artifacts/callbacks/model_checkpoint\\model.h5\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.7104 - accuracy: 0.5581 - val_loss: 0.8044 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MaskImageDetection\\MaskDetectionModel\\Mask\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - ETA: 0s - loss: 0.7622 - accuracy: 0.4651\n",
      "Epoch 2: val_loss improved from 0.80436 to 0.77147, saving model to artifacts/callbacks/model_checkpoint\\model.h5\n",
      "5/5 [==============================] - 22s 5s/step - loss: 0.7622 - accuracy: 0.4651 - val_loss: 0.7715 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.7273 - accuracy: 0.5581\n",
      "Epoch 3: val_loss did not improve from 0.77147\n",
      "5/5 [==============================] - 22s 5s/step - loss: 0.7273 - accuracy: 0.5581 - val_loss: 0.8037 - val_accuracy: 0.4000\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.6921 - accuracy: 0.4884\n",
      "Epoch 4: val_loss did not improve from 0.77147\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.6921 - accuracy: 0.4884 - val_loss: 0.8045 - val_accuracy: 0.4000\n",
      "Epoch 4: early stopping\n",
      "[2024-10-02 19:38:45,976]-INFO-58-Model saved at artifacts\\model_training\\model.h5\n"
     ]
    }
   ],
   "source": [
    "#step7) updating the training pipeline\n",
    "try:\n",
    "    #creating an object of configuration manager class\n",
    "    cm = ConfigurationManager()\n",
    "    callback_config = cm.get_call_model_config()\n",
    "\n",
    "    get_train_config = cm.get_trained_model_config()\n",
    "\n",
    "    #creating an object of CallbackModel\n",
    "    cbm = CallbackModel(callback_config)\n",
    "\n",
    "    lst_obj = cbm.callback()\n",
    "\n",
    "    #creating an object of training model class\n",
    "    tm = ModelTraining(get_train_config)\n",
    "\n",
    "    tm.load_seq_model() #will load sequential model\n",
    "\n",
    "    tm.train_valid_generator() #this method will generate image flowing through directory\n",
    "\n",
    "    tm.train(callback_list=lst_obj)\n",
    "\n",
    "except Exception as e:\n",
    "    raise CustomException(e,sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
